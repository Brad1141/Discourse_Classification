{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (C:\\Users\\Brad\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "100%|██████████| 3/3 [00:00<00:00, 27.77it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets  = load_dataset(\"conll2003\")\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "df_errorIds = pd.read_csv(\"Error_Ids.csv\")\n",
    "df_errorIds = df_errorIds.drop(['Unnamed: 0'], axis = 1)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "tokenDict = {\n",
    "    \"Lead\" : 0,\n",
    "    \"Position\" : 1,\n",
    "    \"Evidence\" : 2,\n",
    "    \"Claim\" : 3,\n",
    "    \"Concluding Statement\" : 4,\n",
    "    \"Counterclaim\" : 5,\n",
    "    \"Rebuttal\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def fileToArray(file_path):\n",
    "    # turn text into array of words\n",
    "    text_ds = tf.data.TextLineDataset(file_path).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "    text_ds = text_ds.enumerate()\n",
    "    docTxt = []\n",
    "    for i in text_ds.as_numpy_iterator():\n",
    "        line = i[1].decode().split()\n",
    "        for l in line:\n",
    "            docTxt.append(l)\n",
    "    \n",
    "    docTxt = ' '.join(docTxt)\n",
    "    return docTxt\n",
    "\n",
    "def calc_word_indices(full_text, discourse_start, discourse_end):\n",
    "    start_index = len(full_text[:discourse_start].split())\n",
    "    token_len = len(full_text[discourse_start:discourse_end].split())\n",
    "    output = list(range(start_index, start_index + token_len))\n",
    "    if output[-1] >= len(full_text.split()):\n",
    "        output = list(range(start_index, start_index + token_len-1))\n",
    "    return output\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def dfTags_to_ints(df):\n",
    "    for index, row in df.iterrows():\n",
    "        intArray = []\n",
    "        tokenArray = []\n",
    "        for i in row[2]:\n",
    "            intArray.append(int(i))\n",
    "        df.at[index, \"ner_tags\"] = intArray.copy()\n",
    "        # for j in row[1]:\n",
    "        #     if j != '.' and j != ',':\n",
    "        #         tokenArray.append(j)\n",
    "        # df.at[index, \"tokens\"] = tokenArray.copy()\n",
    "    return df\n",
    "\n",
    "def csv_to_df(fileName):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in a csv file name and returns a tokenized dataset\n",
    "#NEEDS to be updated in occurance with the createTokenTrainingSet() function\n",
    "def createTokenDataset(fileName):\n",
    "\n",
    "    #maybe create a helper function???\n",
    "    df = csv_to_df(fileName)\n",
    "    essayNames = df[\"id\"].unique()\n",
    "    \n",
    "    data = {\n",
    "        \"id\": [],\n",
    "        \"tokens\": [],\n",
    "        \"ner_tags\": []\n",
    "    }\n",
    "\n",
    "    token_df = pd.DataFrame(data)\n",
    "    for fileName in tqdm(essayNames):\n",
    "        df_file = df[df.id.str.contains(fileName,case=False)]\n",
    "        df_file = df_file.reset_index()\n",
    "        labels = []\n",
    "        num_labels = []\n",
    "        fullText = []\n",
    "        for i in range(len(df_file.index)):\n",
    "            df_string = df_file[\"predictionstring\"][i]\n",
    "            stringArray = df_string.split()\n",
    "            df_textString = df_file[\"discourse_text\"][i].split()\n",
    "            for df in df_textString:\n",
    "                if df != '.' and df != ',':\n",
    "                    fullText.append(df)\n",
    "            for s in stringArray:\n",
    "                labels.append(df_file[\"discourse_type\"][i])\n",
    "                num_labels.append(tokenDict[str(df_file[\"discourse_type\"][i])])\n",
    "\n",
    "        token_df.loc[len(token_df.index)] = [fileName, fullText, num_labels]\n",
    "    \n",
    "    #find a better way to do this\n",
    "    token_df['tokens'] = token_df['tokens'].apply(lambda a: ' '.join(map(str, a)))\n",
    "    token_df['ner_tags'] = token_df['ner_tags'].apply(lambda a: ' '.join(map(str, a)))\n",
    "    token_df['tokens'] = token_df['tokens'].apply(lambda a: a.split())\n",
    "    token_df['ner_tags'] = token_df['ner_tags'].apply(lambda a: a.split())\n",
    "\n",
    "    tokenDataset = Dataset.from_pandas(token_df)\n",
    "\n",
    "    tokenized_datasets = tokenDataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "    )\n",
    "    return tokenized_datasets\n",
    "\n",
    "def createTokenTrainingSet(fileName):\n",
    "    errorList = list(df_errorIds[\"id\"])\n",
    "    df = pd.read_csv(fileName)\n",
    "\n",
    "    df['tokens'] = df['tokens'].apply(lambda a: a.split())\n",
    "    df['ner_tags'] = df['ner_tags'].apply(lambda a: a.split())\n",
    "    df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "    errorList_idx = list(map(lambda e: df.loc[df[\"id\"] == e].index[0], errorList))\n",
    "    df = df.drop(errorList_idx, 0)\n",
    "    df = dfTags_to_ints(df)\n",
    "\n",
    "    newDataset = Dataset.from_pandas(df)\n",
    "\n",
    "    tokenized_datasets = newDataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=newDataset.column_names\n",
    "    )\n",
    "    return tokenized_datasets\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenTrain = createTokenTrainingSet(\"trainHugging4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 13974\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 1553\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenTrain = tokenTrain.train_test_split(train_size=0.9, test_size=0.1)\n",
    "tokenTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Lead\", \"Position\", \"Evidence\", \"Claim\", \"Concluding Statement\", \"Counterclaim\", \"Rebuttal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Claim': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 0},\n",
       " 'Lead': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'overall_precision': 0.5,\n",
       " 'overall_recall': 0.5,\n",
       " 'overall_f1': 0.5,\n",
       " 'overall_accuracy': 0.5}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"B-Lead\", \"B-Lead\"]\n",
    "predictions = [\"B-Lead\", \"B-Claim\"]\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>887.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>That's why there's a thing that's called no te...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>163 164 165 166 167 168 169 170 171 172 173 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>Sometimes on the news there is either an accid...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>211 212 213 214 215 216 217 218 219 220 221 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>Phones are fine to use and it's also the best ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>282 283 284 285 286 287 288 289 290 291 292 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>If you go through a problem and you can't find...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 5</td>\n",
       "      <td>297 298 299 300 301 302 303 304 305 306 307 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>The news always updated when people do somethi...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>355 356 357 358 359 360 361 362 363 364 365 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "5  423A1CA112E2  1.622628e+12            887.0         1150.0   \n",
       "6  423A1CA112E2  1.622628e+12           1151.0         1533.0   \n",
       "7  423A1CA112E2  1.622628e+12           1534.0         1602.0   \n",
       "8  423A1CA112E2  1.622628e+12           1603.0         1890.0   \n",
       "9  423A1CA112E2  1.622628e+12           1891.0         2027.0   \n",
       "\n",
       "                                      discourse_text        discourse_type  \\\n",
       "0  Modern humans today are always on their phone....                  Lead   \n",
       "1  They are some really bad consequences when stu...              Position   \n",
       "2  Some certain areas in the United States ban ph...              Evidence   \n",
       "3  When people have phones, they know about certa...              Evidence   \n",
       "4  Driving is one of the way how to get around. P...                 Claim   \n",
       "5  That's why there's a thing that's called no te...              Evidence   \n",
       "6  Sometimes on the news there is either an accid...              Evidence   \n",
       "7  Phones are fine to use and it's also the best ...                 Claim   \n",
       "8  If you go through a problem and you can't find...              Evidence   \n",
       "9  The news always updated when people do somethi...  Concluding Statement   \n",
       "\n",
       "       discourse_type_num                                   predictionstring  \n",
       "0                  Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1              Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2              Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3              Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4                 Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "5              Evidence 3  163 164 165 166 167 168 169 170 171 172 173 17...  \n",
       "6              Evidence 4  211 212 213 214 215 216 217 218 219 220 221 22...  \n",
       "7                 Claim 2  282 283 284 285 286 287 288 289 290 291 292 29...  \n",
       "8              Evidence 5  297 298 299 300 301 302 303 304 305 306 307 30...  \n",
       "9  Concluding Statement 1  355 356 357 358 359 360 361 362 363 364 365 36...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.loc[df['id'] == \"423A1CA112E2\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myEval(true_labels, true_predictions):\n",
    "    label_dict = []\n",
    "    pred_dict = []\n",
    "    curr_type = true_labels[0][0]\n",
    "    \n",
    "    seqArray = []   \n",
    "    for idx, i in enumerate(true_labels[0]):\n",
    "        if i == curr_type:\n",
    "            seqArray.append(idx)\n",
    "        else:\n",
    "            seqArray.append(idx)\n",
    "            label_dict.append([curr_type, seqArray])\n",
    "            curr_type = i\n",
    "            seqArray = []\n",
    "    \n",
    "    seqArray = []\n",
    "    for idx, i in enumerate(true_predictions[0]):\n",
    "        if i == curr_type:\n",
    "            seqArray.append(idx)\n",
    "        else:\n",
    "            seqArray.append(idx)\n",
    "            pred_dict.append([curr_type, seqArray])\n",
    "            curr_type = i\n",
    "            seqArray = []\n",
    "    \n",
    "    #loop through predictions to find true & false positives\n",
    "    truth_table = {\n",
    "        \"fp\": 0,\n",
    "        \"tp\": 0,\n",
    "        \"fn\": 0\n",
    "    }\n",
    "    for p in pred_dict:\n",
    "        foundMatch = False\n",
    "        for l in label_dict:\n",
    "            if p[0] == l[0] and len(list(set(p[1]) & set(l[1]))) > len(p) / 2:\n",
    "                foundMatch = True\n",
    "        \n",
    "        if foundMatch:\n",
    "            truth_table[\"tp\"] = truth_table[\"tp\"] + 1\n",
    "        else:\n",
    "            truth_table[\"fp\"] = truth_table[\"fp\"] + 1\n",
    "\n",
    "    #loop through labels to find false negatives\n",
    "    for l in label_dict:\n",
    "        foundMatch = False\n",
    "        for p in pred_dict:\n",
    "            if l[0] == p[0] and len(list(set(l[1]) & set(p[1]))) >= len(l) / 2:\n",
    "                foundMatch = True\n",
    "        \n",
    "        if not foundMatch:\n",
    "            truth_table[\"fn\"] = truth_table[\"fn\"] + 1\n",
    "\n",
    "    precision = truth_table[\"tp\"] / (truth_table[\"tp\"] + truth_table[\"fp\"])\n",
    "    recall = truth_table[\"tp\"] / (truth_table[\"tp\"] + truth_table[\"fn\"])\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    precision, recall, f1_score = myEval(true_labels, true_predictions)\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1_score,\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsTest = [['Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Position', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Counterclaim', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Rebuttal', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Concluding Statement', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Concluding Statement', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Claim', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Evidence', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement', 'Concluding Statement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABELS\n",
      "['Position', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
      "['Evidence', [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]]\n",
      "['Counterclaim', [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]]\n",
      "['Rebuttal', [98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116]]\n",
      "['Claim', [117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137]]\n",
      "['Concluding Statement', [138]]\n",
      "['Claim', [139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155]]\n",
      "['Concluding Statement', [156]]\n",
      "['Claim', [157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]]\n",
      "['Evidence', [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285]]\n"
     ]
    }
   ],
   "source": [
    "label_dict = []\n",
    "curr_type = labelsTest[0][0]\n",
    "seqArray = []   \n",
    "for idx, i in enumerate(labelsTest[0]):\n",
    "    if i == curr_type:\n",
    "        seqArray.append(idx)\n",
    "    else:\n",
    "        seqArray.append(idx)\n",
    "        label_dict.append([curr_type, seqArray])\n",
    "        curr_type = i\n",
    "        seqArray = []\n",
    "        \n",
    "print(\"TRUE LABELS\")\n",
    "for i in label_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict = label_dict.copy()\n",
    "test1 = [1, 2, 3]\n",
    "test2 = [2, 3, 4, 5]\n",
    "# list(set(test1) & set(test2))\n",
    "int(len(test1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#loop through predictions to find true & false positives\n",
    "truth_table = {\n",
    "    \"fp\": 0,\n",
    "    \"tp\": 0,\n",
    "    \"fn\": 0\n",
    "}\n",
    "for p in pred_dict:\n",
    "    foundMatch = False\n",
    "    for l in label_dict:\n",
    "        if p[0] == l[0] and len(list(set(p[1]) & set(l[1]))) > len(p) / 2:\n",
    "            foundMatch = True\n",
    "    \n",
    "    if foundMatch:\n",
    "        truth_table[\"tp\"] = truth_table[\"tp\"] + 1\n",
    "    else:\n",
    "        truth_table[\"fp\"] = truth_table[\"fp\"] + 1\n",
    "\n",
    "#loop through labels to find false negatives\n",
    "for l in label_dict:\n",
    "    foundMatch = False\n",
    "    for p in pred_dict:\n",
    "        if l[0] == p[0] and len(list(set(l[1]) & set(p[1]))) >= len(l) / 2:\n",
    "            foundMatch = True\n",
    "    \n",
    "    if not foundMatch:\n",
    "        truth_table[\"fn\"] = truth_table[\"fn\"] + 1\n",
    "\n",
    "precision = truth_table[\"tp\"] / (truth_table[\"tp\"] + truth_table[\"fp\"])\n",
    "recall = truth_table[\"tp\"] / (truth_table[\"tp\"] + truth_table[\"fn\"])\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingCSV = pd.read_csv(\"train.csv\")\n",
    "trainingCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "true_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallToken = tokenTrain[\"train\"][:10]\n",
    "smallToken = Dataset.from_dict(smallToken)\n",
    "smallToken = smallToken.train_test_split(train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=smallToken[\"train\"],\n",
    "    eval_dataset=smallToken[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVERYTHING BELOW IS NOT USEFUL, CANNOT INSTALL GIT-LFS ON WINDOWS, USE COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "with open('test/0FB0700DAF44.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   9%|▉         | 52.5M/570M [00:05<00:51, 10.5MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-41335511d813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"brad1141/bert-finetuned-ner\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlongformer_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allenai/longformer-base-4096\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m token_classifier = pipeline(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;34m\"token-classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlongformer_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"simple\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[1;31m# Will load the correct model if possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[0mmodel_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m     framework, model = infer_framework_load_model(\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmodel_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         raise ValueError(\n\u001b[0;32m    443\u001b[0m             \u001b[1;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m                 \u001b[1;31m# Load from URL or cache if already cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                 resolved_archive_file = cached_path(\n\u001b[0m\u001b[0;32m   1330\u001b[0m                     \u001b[0marchive_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m                     \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m         output_path = get_from_cache(\n\u001b[0m\u001b[0;32m   1777\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   2038\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m             \u001b[0mhttp_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"storing {url} in cache at {cache_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     )\n\u001b[1;32m-> 1899\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# filter out keep-alive new chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m                 if (\n\u001b[0;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   9%|▉         | 52.7M/570M [00:19<00:51, 10.5MB/s]"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"brad1141/bert-finetuned-ner\"\n",
    "longformer_checkpoint = \"allenai/longformer-base-4096\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=longformer_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "predicts = token_classifier(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n"
     ]
    }
   ],
   "source": [
    "def calc_word_indices(full_text, discourse_start, discourse_end):\n",
    "    start_index = len(full_text[:discourse_start].split())\n",
    "    token_len = len(full_text[discourse_start:discourse_end].split())\n",
    "    output = list(range(start_index, start_index + token_len))\n",
    "    if output[-1] >= len(full_text.split()):\n",
    "        output = list(range(start_index, start_index + token_len-1))\n",
    "    return output\n",
    "\n",
    "outputt = calc_word_indices(data, 0, 13)\n",
    "outputt = \" \".join(str(x) for x in outputt)\n",
    "print(outputt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, class, predictionstring]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'id':[],\n",
    "        'class': [],\n",
    "        'predictionstring':[]}\n",
    "sub_df = pd.DataFrame(dict)\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000D23A521A.txt'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNames = os.listdir('train')\n",
    "fileNames = fileNames[:10000]\n",
    "fileNames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_format(fileName):\n",
    "    data = \"\"\n",
    "    with open('train/' + fileName, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "    \n",
    "    predicts = token_classifier(data)\n",
    "\n",
    "    for p in predicts:\n",
    "        word_Indices_Array = calc_word_indices(data, p[\"start\"], p[\"end\"])\n",
    "        word_Indices_String = \" \".join(str(x) for x in word_Indices_Array)\n",
    "        word_class = p[\"entity_group\"]\n",
    "        word_id = fileName[:-4]\n",
    "        sub_df.loc[len(sub_df.index)] = [word_id, word_class, word_Indices_String]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(fileNames):\n",
    "    predict_and_format(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c931ba401747e1100110d99c7b2e1195adf3961a7e00160e720e39c4d164b397"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
